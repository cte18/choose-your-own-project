---
title: "Data Science Capstone Project: Predicting Heart Disease"
author: "Catherine Edis"
date: "8 March 2022"
urlcolor: blue
output:
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, fig.height = 3, fig.width = 6, fig.align = 'center', strip.white = FALSE)

```

***  


# Introduction
## Purpose

This project was undertaken to fulfill the requirements of the "Data Science: Capstone" course, which is part of the Professional Certificate in Data Science program offered by Harvard University through edX. The purpose of the project was to solve a chosen problem using a publicly-available dataset and the machine learning techniques explained in the Professional Certificate program. The machine learning techniques used must include more than just standard linear regression. 


## Heart Disease Data

The project used a dataset of heart disease observations that was originally collected by the Cleveland Clinic Foundation (principal investigator: Robert Detrano, M.D., Ph.D.). The dataset was published on the UC Irvine Machine Learning Repository by David Aha in 1988. It is available at: https://archive.ics.uci.edu/ml/datasets/Heart+Disease 

The *processed.cleveland.data* dataset was used for this project, because it was relatively clean and complete. (It contains relatively few missing or "dummy" values compared to the other datasets published at the above site.)

As described in the *heart-disease.names* file provided with the dataset, the dataset includes 303 observations, with 14 attributes (described below). Each observation relates to an individual patient, and includes physiological information collected while they underwent supervised tests, including a thallium stress test (also known as a nuclear stress test). A thallium stress test is a nuclear imaging test that shows how well blood flows around the patient's heart while they are exercising or at rest.^[https://www.healthline.com/health/thallium-stress-test]
\newline

Attribute | Description                                        | Type
--------- | -------------------------------------------------- | ----
age       | Age of the patient, in years                       | Numerical
sex       | Sex of the patient                                 | Categorical
cp        | Type of chest pain                                 | Categorical
trestbps	| Resting blood pressure                             | Numerical
chol 	    | Serum cholesterol                                  | Numerical
fbs	      | Fasting blood sugar                                | Categorical
restecg	  | Resting electrocardiographic (ECG) results         | Categorical
thalach	  | Maximum heart rate achieved                        | Numerical
exang	    | Exercise-induced angina                            | Categorical
oldpeak	  | ST depression induced by exercise relative to rest | Numerical
slope	    | Slope of peak exercise ST segment                  | Categorical
ca	      | Number of major vessels colored by fluoroscopy     | Numerical
thal	    | Thallium stress test result                        | Categorical
target    | Heart disease diagnosis                            | Categorical

The attributes are discussed in more detail in the *Analysis* section below.

## Goal of the Project
The aim of this project was to explore a number of different models that might be used to predict the presence of heart disease, and identify the model that produces the most accurate predictions, using the Cleveland heart disease dataset. 

## Key Steps Performed 
The following key steps were performed.

1.	Load the dataset.

2.	Initial examination of the structure and content of the dataset.

3.	Perform some basic checks on the quality of the data (for example, check for any missing values).

4.	Where required, reformat the data to make it easier to work with.

5.  Explore the dataset further, to better understand the nature of the data and identify attributes that could be used as potential predictors in the modelling.

6.	Set up the objects required for modelling, including a training and test set generated from the original dataset.

7.	Use the training set to develop and train various prediction models, and run them against the test set.

8.	Compare the accuracy of the models when run against the test set, and identify the one that produces the most accurate results.


These steps and the results that were produced are described in more detail in the following sections.

## Acknowledgments

The author wishes to acknowledge the following:

* for the collection of the original data: Cleveland Clinic Foundation, Principal Investigator Robert Detrano, M.D., Ph.D., et al.

* for the UC Irvine Machine Learning Repository: Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

* for the Heart Disease dataset published on the UC Irvine Machine Learning Repository: David Aha.


# Analysis

## Preparation

Before beginning the analysis, any required libraries were installed and loaded.  


```{r load-libraries, message=FALSE}

#########################################################################################
# Install any packages required.
#########################################################################################

if(!require(tidyverse))
  install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret))
  install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table))
  install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(scales)) 
  install.packages("scales", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) 
  install.packages("lubridate", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)
library(scales)
library(lubridate)


```


A copy of the processed Cleveland heart disease dataset was then loaded, and the *cleveland_heart_disease* set/table created for use in the analysis.


```{r cyo-dataset, echo=TRUE, message=FALSE}

#########################################################################################
# 
# Load the dataset.
#
# The original dataset is available in the UCI Machine Learning Repository, at:
# https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease
# 
# This project uses a copy of the dataset, which was uploaded to a GitHub repository,
# along with the project report and the associated scripts.
# 
#########################################################################################

# Read in the data from the "processed.cleveland.data" file.
cleveland_heart_disease <- read.csv("processed.cleveland.data", 
                                    header = FALSE, sep = ",", stringsAsFactors = FALSE)

# The data file does not contain a header row, so the attribute/column names need to be
# set, using the information provided with the dataset in the "heart-disease.names" file.

column_names <- c("age", "sex",	"cp",	"trestbps",	"chol",	"fbs", "restecg",
                  "thalach", "exang", "oldpeak", "slope", "ca", "thal", "target")
colnames(cleveland_heart_disease) <- column_names


```
  

## Initial Examination of the Data  

The dataset was examined to understand and confirm its structure, including the:

* class of the dataset;

* number of observations (rows);

* number of attributes (columns); and,

* name and class of each attribute.
\newline 


```{r dataset-structure}

# Examine the structure of the dataset.
str(cleveland_heart_disease)


```


The first few rows of the dataset were examined to view some examples of content.  


```{r dataset-example-rows}

# To see some example data, view the first few rows of the sets.
knitr::kable(head(cleveland_heart_disease, 10))


```


The dataset was then checked for missing values. The documentation that was supplied with the original dataset indicated that there were some missing values, and each of them was set to "?". The dataset was therefore checked for values of both "NA" and "?".


```{r check_missing_values}

# Check for any missing ("NA") values in any column.
apply(cleveland_heart_disease, 2, function(x) any(is.na(x)))

# Check for any values containing a "?".
apply(cleveland_heart_disease, 2, function(x) any(x=="?"))


```


The initial examination confirmed that:

1. The dataset contained 303 observations and 14 variables.

2. Each row appears to contain an observation for one patient.

3. The dataset contains no "NA" values.

4. The dataset contains some "?" values (used to denote missing values) in the *ca* and *thal* columns.


## Reformatting the Dataset

After the initial examination, the dataset was reformatted to make it easier to work with, as follows:

* Rows that contained "?" values were removed.

* The *target* attribute (the attribute the modelling attempted to predict), was converted to a binary value that simply indicated whether or not heart disease had been diagnosed in the patient. 

* Columns that corresponded to categorical attributes were converted to factors.

* Labels were defined for factor levels, based on the information provided in the documentation that accompanied the original dataset.


```{r reformat-data}

#########################################################################################
# Reformat the data to make it easier to work with.
#########################################################################################

# Remove the rows with "?" values.
cleveland_heart_disease <- cleveland_heart_disease %>% filter(ca!="?" & thal !="?")

# Because the "ca" and "thal" columns contained "?", they were both loaded as type
# "character" initially. They can now be converted to numerics.
cleveland_heart_disease$ca <- as.numeric(cleveland_heart_disease$ca)
cleveland_heart_disease$thal <- as.numeric(cleveland_heart_disease$thal)

# Convert the "target" attribute to a binary value where:
#    0 indicates no heart disease is present
#    1 indicates some heart disease is present
#
# Note: This is the attribute that the models will be trained to predict.

cleveland_heart_disease <- cleveland_heart_disease %>% 
  mutate(target = ifelse(target >= 1, 1, 0))

# Several of the attributes in the dataset are categorical. 
# Convert the categorical attributes from numeric to factor.
categorical_column_names <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "thal",
                              "target")
cleveland_heart_disease[categorical_column_names] <- 
  lapply(cleveland_heart_disease[categorical_column_names], factor)

# Define level names for the "sex" attribute, to make plotting easier.
levels(cleveland_heart_disease$sex)[levels(cleveland_heart_disease$sex)==0] <- 
  "Female"
levels(cleveland_heart_disease$sex)[levels(cleveland_heart_disease$sex)==1] <- 
  "Male"

# Define level names for the "cp" attribute, to make plotting easier.
levels(cleveland_heart_disease$cp)[levels(cleveland_heart_disease$cp)==1] <- 
  "Typical Angina"
levels(cleveland_heart_disease$cp)[levels(cleveland_heart_disease$cp)==2] <- 
  "Atypical Angina"
levels(cleveland_heart_disease$cp)[levels(cleveland_heart_disease$cp)==3] <- 
  "Non-Anginal Pain"
levels(cleveland_heart_disease$cp)[levels(cleveland_heart_disease$cp)==4] <- 
  "Asymptomatic"

# Define level names for the "fbs" attribute, to make plotting easier.
levels(cleveland_heart_disease$fbs)[levels(cleveland_heart_disease$fbs)==0] <- 
  "<= 120 mg/dl"
levels(cleveland_heart_disease$fbs)[levels(cleveland_heart_disease$fbs)==1] <- 
  "> 120 mg/dl"

# Define level names for the "restecg" attribute, to make plotting easier.
levels(cleveland_heart_disease$restecg)[levels(cleveland_heart_disease$restecg)==0] <- 
  "Normal"
levels(cleveland_heart_disease$restecg)[levels(cleveland_heart_disease$restecg)==1] <- 
  "ST-T Wave Abnormality"
levels(cleveland_heart_disease$restecg)[levels(cleveland_heart_disease$restecg)==2] <- 
  "Left Ventricular Hypertrophy"

# Define level names for the "exang" attribute, to make plotting easier.
levels(cleveland_heart_disease$exang)[levels(cleveland_heart_disease$exang)==0] <- 
  "No"
levels(cleveland_heart_disease$exang)[levels(cleveland_heart_disease$exang)==1] <- 
  "Yes"

# Define level names for the "slope" attribute, to make plotting easier.
levels(cleveland_heart_disease$slope)[levels(cleveland_heart_disease$slope)==1] <- 
  "Upsloping"
levels(cleveland_heart_disease$slope)[levels(cleveland_heart_disease$slope)==2] <- 
  "Flat"
levels(cleveland_heart_disease$slope)[levels(cleveland_heart_disease$slope)==3] <- 
  "Downsloping"

# Define level names for the "thal" attribute, to make plotting easier.
levels(cleveland_heart_disease$thal)[levels(cleveland_heart_disease$thal)==3] <- 
  "Normal"
levels(cleveland_heart_disease$thal)[levels(cleveland_heart_disease$thal)==6] <- 
  "Fixed Defect"
levels(cleveland_heart_disease$thal)[levels(cleveland_heart_disease$thal)==7] <- 
  "Reversible Defect"

# Define level names for the "target" attribute, to make plotting easier.
levels(cleveland_heart_disease$target)[levels(cleveland_heart_disease$target)==0] <- 
  "No Heart Disease"
levels(cleveland_heart_disease$target)[levels(cleveland_heart_disease$target)==1] <- 
  "Heart Disease"


```

The structure of the reformatted dataset was then examined and confirmed.

```{r reformatted-structure}

# Examine and confirm the structure of the reformatted dataset.
str(cleveland_heart_disease)


```

After reformatting, the dataset had:

* 297 rows (6 rows originally contained "?" values and had therefore been removed); 

* 8 attributes with a type of *factor*, and with the factor levels labelled appropriately (for the 8 categorical attributes); and, 

* 6 attributes with a type of *number* (for the 6 numerical attributes).


## Further Exploration of the Data

The dataset was then explored further, to better understand the nature of the data.

Note: In the interests of readability, the R code used to generate the following tables and graphs was not displayed in this report. It can be viewed in the associated R and R Markdown scripts. 

First, the number of patients with and without heart disease was calculated.
\newline

```{r explore-heart-disease, echo=FALSE, message=FALSE}

# Display the total number of patients with and without heart disease.
count_by_target <- cleveland_heart_disease %>% 
  count(target) %>% 
  rename("Presence of Heart Disease" = target, "Count" = n)
knitr::kable(count_by_target, 
             caption = "Number of Patients with and without Heart Disease")

```

There was a reasonable number of patients in both categories, which was useful for modelling purposes.

Next, each attribute was examined for any obvious correlation between it and the presence of heart disease. The method used to do this differed depending on whether the attribute was numerical or categorical.

For each numerical attribute, a density plot was generated that showed the distribution of patients with and without heart disease (in red and green respectively), overlaid on each other. This visually showed whether there were any obvious differences across the values.

For each categorical attribute:

1. A bar graph was generated to show the proportion of patients with and without heart disease (in red and green respectively), grouped by each value of the categorical attribute. This visually showed whether there were any obvious differences in proportions across the categories.

2. The number of patients for each value of the categorical attribute was calculated. This assisted the interpretation of the associated bar graph, because a noticeable variation across categories might be due to an individual category having a very small number of observations.
\newline

```{r explore-age, echo=FALSE, message=FALSE}

################################
# Age
################################

cleveland_heart_disease %>%
  ggplot(aes(age, fill = target)) +
  geom_density(alpha = 0.4) +
  ggtitle(label = "Age (in years)", subtitle = " ") +
  xlab(NULL) +
  ylab("Density") + 
  scale_fill_manual(name="Legend", values = c("darkseagreen3", "indianred2")) + 
  theme(legend.position = "right")


```

The density plot for age showed some distinction between the plots for patients with and without heart disease. This suggested there may have been some correlation between the two.
\newline

```{r explore-sex, echo=FALSE, message=FALSE, fig.width = 5}

################################
# Sex
################################

cleveland_heart_disease %>% 
  group_by(sex,target) %>% 
  summarise(count=n()) %>% 
  mutate(percentage = count/sum(count)) %>%
  ggplot(aes(sex, y = percentage, fill = target)) +
  geom_bar(stat = "identity") + 
  ggtitle(label = "Sex (Female or Male)", subtitle = " ") +
  xlab(NULL) +
  scale_y_continuous(name = "Percentage with / without Heart Disease", 
                     labels = label_percent()) +
  scale_fill_manual(name = "Legend", values = c("darkseagreen3", "indianred2")) +
  theme(legend.position = "right")

count_by_sex <- cleveland_heart_disease %>% 
  count(sex) %>% 
  rename("Sex" = sex, "Count" = n)
knitr::kable(count_by_sex, 
             caption = "Number of patients grouped by sex (female or male).")


```

The bar graph above indicated that male patients in the Cleveland dataset were around twice as likely to have heart disease than the female patients. While there were more than double the number of men than women, the number of female patients (96) was not insignificant. This suggested that *sex* had some predictive power in relation to heart disease.
\newline

```{r explore-cp, echo=FALSE, message=FALSE, fig.width = 7}

################################
# Type of Chest pain (cp)
################################

cleveland_heart_disease %>% 
  group_by(cp,target) %>% 
  summarise(count=n()) %>% 
  mutate(percentage = count/sum(count)) %>%
  ggplot(aes(cp, y = percentage, fill = target)) +
  geom_bar(stat = "identity") + 
  ggtitle(label = "Type of Chest Pain", subtitle = " ") +
  xlab(NULL) +
  scale_y_continuous(name = "Percentage with / without Heart Disease", 
                     labels = label_percent()) +
  scale_fill_manual(name = "Legend", values = c("darkseagreen3", "indianred2")) +
  theme(legend.position = "right")

count_by_cp <- cleveland_heart_disease %>% 
  count(cp) %>% 
  rename("Chest Pain" = cp, "Count" = n)
knitr::kable(count_by_cp, 
             caption = "Number of patients grouped by chest pain category.")

```

There appeared to be some correlation between the type of chest pain experienced by a patient and the presence of heart disease. Notably, patients who reported **no** chest pain were much **more** likely to have heart disease than patients who reported some form of chest pain; and the number of patients in the dataset who were asymptomatic was relatively high.
\newline

```{r explore-trestbps, echo=FALSE, message=FALSE}

################################
# Resting blood pressure (trestbps)
################################

cleveland_heart_disease %>%
  ggplot(aes(trestbps, fill = target)) +
  geom_density(alpha = 0.4) +
  ggtitle(label = "Resting Blood Pressure (in mm Hg)", subtitle = " ") +
  xlab(NULL) +
  ylab("Density") + 
  scale_fill_manual(name="Legend", values = c("darkseagreen3", "indianred2")) + 
  theme(legend.position = "right")


```

The density plot for resting blood pressure showed no significant distinction between patients who did and did not have heart disease. This attribute therefore appeared to have little, if any, correlation with heart disease.
\newline


```{r explore-chol, echo=FALSE, message=FALSE}

################################
# Serum cholesterol (chol)
################################

cleveland_heart_disease %>%
  ggplot(aes(chol, fill = target)) +
  geom_density(alpha = 0.4) +
  ggtitle(label = "Serum Cholesterol (in mg/dl)", subtitle = " ") +
  xlab(NULL) +
  ylab("Density") + 
  scale_fill_manual(name="Legend", values = c("darkseagreen3", "indianred2")) + 
  theme(legend.position = "right")


```


Similarly, the density plot for serum cholesterol showed little distinction between patients who did and did not have heart disease. This attribute therefore appeared to have little correlation with heart disease.
\newline


```{r explore-fbs, echo=FALSE, message=FALSE, fig.width = 5}

################################
# Fasting blood sugar (fbs)
################################

cleveland_heart_disease %>% 
  group_by(fbs,target) %>% 
  summarise(count=n()) %>% 
  mutate(percentage = count/sum(count)) %>%
  ggplot(aes(fbs, y = percentage, fill = target)) +
  geom_bar(stat = "identity") + 
  ggtitle(label = "Fasting Blood Sugar", subtitle = " ") +
  xlab(NULL) +
  scale_y_continuous(name = "Percentage with / without Heart Disease", 
                     labels = label_percent()) +
  scale_fill_manual(name = "Legend", values = c("darkseagreen3", "indianred2")) +
  theme(legend.position = "right")

count_by_fbs <- cleveland_heart_disease %>% 
  count(fbs) %>% 
  rename("Fasting Blood Sugar" = fbs, "Count" = n)
knitr::kable(count_by_fbs, 
             caption = "Number of patients grouped by fasting blood sugar category.")


```

The proportion of patients who did/did not have heart disease was virtually identical, regardless of their fasting blood sugar category. This attribute therefore appeared to have no correlation with heart disease.
\newline


```{r explore-restecg, echo=FALSE, message=FALSE, fig.width = 7.5}

################################
# Resting ECG (restecg)
################################

cleveland_heart_disease %>% 
  group_by(restecg,target) %>% 
  summarise(count=n()) %>% 
  mutate(percentage = count/sum(count)) %>%
  ggplot(aes(restecg, y = percentage, fill = target)) +
  geom_bar(stat = "identity") + 
  ggtitle(label = "Resting ECG", subtitle = " ") +
  xlab(NULL) +
  scale_y_continuous(name = "Percentage with / without Heart Disease", 
                     labels = label_percent()) +
  scale_fill_manual(name = "Legend", values = c("darkseagreen3", "indianred2")) +
  theme(legend.position = "right")

count_by_restecg <- cleveland_heart_disease %>% 
  count(restecg) %>% 
  rename("Resting ECG" = restecg, "Count" = n)
knitr::kable(count_by_restecg, 
             caption = "Number of patients grouped by resting ECG category.")


```


The bar graph above suggested that patients who had a resting ECG result that indicated an ST-T wave abnormality were significantly more likely to have heart disease than patients with a "normal" resting ECG result. However, there were only four patients in the former group, so this inference should be treated with caution. The number of patients with a result that indicated left ventricular hypertrophy was more significant, and based on the bar graph above, this did appear to have some correlation with the presence of heart disease.
\newline


```{r explore-thalach, echo=FALSE, message=FALSE}

################################
# Maximum Heart Rate Achieved (thalach)
################################

cleveland_heart_disease %>%
  ggplot(aes(thalach, fill = target)) +
  geom_density(alpha = 0.4) +
  ggtitle(label = "Maximum Heart Rate Achieved (in beats per minute)", 
          subtitle = " ") +
  xlab(NULL) +
  ylab("Density") + 
  scale_fill_manual(name="Legend", values = c("darkseagreen3", "indianred2")) + 
  theme(legend.position = "right")


```


The density plot for maximum heart rate achieved showed some distinction between patients who did and did not have heart disease. This attribute therefore appeared to have some correlation with heart disease.
\newline


```{r explore-exang, echo=FALSE, message=FALSE, fig.width = 5}

################################
# Exercise-induced angina (exang)
################################

cleveland_heart_disease %>% 
  group_by(exang,target) %>% 
  summarise(count=n()) %>% 
  mutate(percentage = count/sum(count)) %>%
  ggplot(aes(exang, y = percentage, fill = target)) +
  geom_bar(stat = "identity") + 
  ggtitle(label = "Exercise-Induced Angina", subtitle = " ") +
  xlab(NULL) +
  scale_y_continuous(name = "Percentage with / without Heart Disease", 
                     labels = label_percent()) +
  scale_fill_manual(name = "Legend", values = c("darkseagreen3", "indianred2")) +
  theme(legend.position = "right")

count_by_exang <- cleveland_heart_disease %>% 
  count(exang) %>% 
  rename("Exercise-Induced Angina" = exang, "Count" = n)
knitr::kable(count_by_exang, 
             caption = "Number of patients grouped by exercise-induced angina category.")


```


The bar graph above indicated that patients who experienced exercise-induced angina were more than twice as likely to have heart disease. This indicated considerable correlation between exercise-induced angina and heart disease.
\newline


```{r explore-oldpeak, echo=FALSE, message=FALSE}

################################
# ST depression induced by exercise relative to rest (oldpeak)
################################

cleveland_heart_disease %>%
  ggplot(aes(oldpeak, fill = target)) +
  geom_density(alpha = 0.4) +
  ggtitle(label = "ST Depression Induced by Exercise Relative to Rest", 
          subtitle = " ") +
  xlab(NULL) +
  ylab("Density") + 
  scale_fill_manual(name="Legend", values = c("darkseagreen3", "indianred2")) + 
  theme(legend.position = "right")


```


The density plot for ST depression induced by exercise relative to rest above showed some distinction between patients who did and did not have heart disease. This attribute therefore appeared to have some correlation with heart disease.
\newline


```{r explore-slope, echo=FALSE, message=FALSE}

################################
# Slope of peak exercise ST segment (slope)
################################

cleveland_heart_disease %>% 
  group_by(slope,target) %>% 
  summarise(count=n()) %>% 
  mutate(percentage = count/sum(count)) %>%
  ggplot(aes(slope, y = percentage, fill = target)) +
  geom_bar(stat = "identity") + 
  ggtitle(label = "Slope of Peak Exercise ST Segment", subtitle = " ") +
  xlab(NULL) +
  scale_y_continuous(name = "Percentage with / without Heart Disease", 
                     labels = label_percent()) +
  scale_fill_manual(name = "Legend", values = c("darkseagreen3", "indianred2")) +
  theme(legend.position = "right")

count_by_slope <- cleveland_heart_disease %>% 
  count(slope) %>% 
  rename("Slope of Peak Exercise ST Segment" = slope, "Count" = n)
knitr::kable(count_by_slope, 
             caption = "Number of patients grouped by slope of peak exercise ST segment.")


```


There appeared to be considerable correlation between the slope of peak exercise ST segment and the presence of heart disease - patients for whom it was upsloping were less than half as likely to have heart disease than other patients.
\newline


```{r explore-ca, echo=FALSE, message=FALSE}

################################
# Number of Major Vessels Colored by Fluoroscopy (ca)
################################

cleveland_heart_disease %>%
  ggplot(aes(ca, fill = target)) +
  geom_density(alpha = 0.4) +
  ggtitle(label = "Number of Major Vessels Colored by Fluoroscopy", subtitle = " ") +
  xlab(NULL) +
  ylab("Density") + 
  scale_fill_manual(name="Legend", values = c("darkseagreen3", "indianred2")) + 
  theme(legend.position = "right")


```


The density plot for the number of major vessels colored by fluoroscopy showed some distinction between patients who did and did not have heart disease. This attribute therefore appeared to have some correlation with heart disease.
\newline


```{r explore-thal, echo=FALSE, message=FALSE}

################################
# Thallium stress test result (thal)
################################

cleveland_heart_disease %>% 
  group_by(thal,target) %>% 
  summarise(count=n()) %>% 
  mutate(percentage = count/sum(count)) %>%
  ggplot(aes(thal, y = percentage, fill = target)) +
  geom_bar(stat = "identity") + 
  ggtitle(label = "Thallium Stress Test Result", subtitle = " ") +
  xlab(NULL) +
  scale_y_continuous(name = "Percentage with / without Heart Disease", 
                     labels = label_percent()) +
  scale_fill_manual(name = "Legend", values = c("darkseagreen3", "indianred2")) +
  theme(legend.position = "right")

count_by_thal <- cleveland_heart_disease %>% 
  count(thal) %>% 
  rename("Thallium Stress Test Result" = thal, "Count" = n)
knitr::kable(count_by_thal, 
             caption = "Number of patients grouped by thallium stress test result.")


```

Finally, there appeared to be considerable correlation between a patient's thallium stress test results (in relation to any defects found) and the presence of heart disease. Patients for whom it was "normal" were almost two thirds **less** likely to have heart disease than other patients.
\newline

After the above exploration of the data was completed, it appeared that the following attributes were most likely to be potential predictors for the presence of heart disease:

* Age of the patient (*age* - numerical)

* Sex of the patient (*sex* - categorical)

* Type of chest pain (*cp* - categorical)

* Resting electrocardiographic results (*restecg* - categorical)

* Maximum heart rate achieved (*thalach* - numerical)

* Exercise-induced angina (*exang* - categorical)

* ST depression induced by exercise relative to rest (*oldpeak* - numerical)

* Slope of the peak exercise ST segment (*slope* - categorical)

* Number of major vessels colored by fluoroscopy (*ca* - numerical)

* Thallium stress test result (*thal* - categorical)



## Modelling Approach

Several types of modelling were then explored to determine how accurately they predicted heart disease. Each model was first trained using a training subset of the *cleveland_heart_disease* dataset. Then, each model was applied to a separate, test, subset of the *cleveland_heart_disease* dataset, and the accuracy of its predictions assessed. 

The accuracy of each model's predictions was determined using the "overall accuracy" calculated in a confusion matrix. "Overall accuracy" reported the proportion of observations in the test set that were correctly predicted by the model.


The following types of models were explored:

* Generalized Linear Model (glm)

* Linear Discriminant Analysis (lda)

* k-Nearest Neighbors (knn)

* Classification and Regression Tree (rpart)

* Random Forest (rf)

The training and test sets were created by partitioning the reformatted *cleveland_heart_disease* dataset into a *heart_train_set* and *heart_test_set*, each of which comprised 50% of the reformatted dataset. A 50/50 split was chosen to ensure there were enough observations in the test set to adequately validate the models. 


```{r setup-objects, warning = FALSE}

#########################################################################################
# Set up the objects required for the modelling.
#########################################################################################

# Create training and test sets from the "cleveland_heart_disease" set.

# The following line of code assumes that R 3.6 or later is being used.
set.seed(1, sample.kind = "Rounding") 

heart_test_index <- createDataPartition(y = cleveland_heart_disease$target, 
                                        times = 1, p = 0.5, list = FALSE)
heart_train_set <- cleveland_heart_disease %>% slice(-heart_test_index)
heart_test_set <- cleveland_heart_disease %>% slice(heart_test_index)


```


```{r training-set-structure}

# Display the structure of the new training set.
str(heart_train_set)


```


```{r test-set-structure}

# Display the structure of the new test set.
str(heart_test_set)


```



Having created the training and test sets, each model was then run, and the results recorded.

```{r run-models}

#########################################################################################
# Apply different models to try to predict whether or not the patient has heart disease.
#########################################################################################

# Generalized Linear Model (glm)
fit_glm <- train(target ~ ., method ="glm", data = heart_train_set)
y_hat_glm <- predict(fit_glm, heart_test_set, type = "raw")
cm_glm <- confusionMatrix(data = y_hat_glm, reference = heart_test_set$target)

model_results <- tibble(Method = "Generalized Linear Model", 
                        Accuracy = cm_glm$overall[["Accuracy"]],
                        Sensitivity = cm_glm$byClass[["Sensitivity"]],
                        Specificity = cm_glm$byClass[["Specificity"]])

# Linear Discriminant Analysis (lda)
fit_lda <- train(target ~ ., method ="lda", data = heart_train_set)
y_hat_lda <- predict(fit_lda, heart_test_set, type = "raw")
cm_lda <- confusionMatrix(data = y_hat_lda, reference = heart_test_set$target)

model_results <- bind_rows(model_results, 
                           tibble(Method="Linear Discriminant Analysis",
                                  Accuracy = cm_lda$overall[["Accuracy"]],
                                  Sensitivity = cm_lda$byClass[["Sensitivity"]],
                                  Specificity = cm_lda$byClass[["Specificity"]]))

# k-Nearest Neighbors (knn)
fit_knn <- train(target ~ ., method ="knn", data = heart_train_set)
y_hat_knn <- predict(fit_knn, heart_test_set, type = "raw")
cm_knn <- confusionMatrix(data = y_hat_knn, reference = heart_test_set$target)

model_results <- bind_rows(model_results, 
                           tibble(Method="k-Nearest Neighbors",
                                  Accuracy = cm_knn$overall[["Accuracy"]],
                                  Sensitivity = cm_knn$byClass[["Sensitivity"]],
                                  Specificity = cm_knn$byClass[["Specificity"]]))

# Classification and Regression Tree (rpart)
fit_rpart <- train(target ~ ., method ="rpart", data = heart_train_set)
y_hat_rpart <- predict(fit_rpart, heart_test_set, type = "raw")
cm_cart <- confusionMatrix(data = y_hat_rpart, reference = heart_test_set$target)

model_results <- bind_rows(model_results, 
                           tibble(Method="Classification and Regression Tree",
                                  Accuracy = cm_cart$overall[["Accuracy"]],
                                  Sensitivity = cm_cart$byClass[["Sensitivity"]],
                                  Specificity = cm_cart$byClass[["Specificity"]]))

# Random Forest (rf)
fit_rf <- train(target ~ ., method ="rf", data = heart_train_set)
y_hat_rf <- predict(fit_rf, heart_test_set, type = "raw")
cm_rf <- confusionMatrix(data = y_hat_rf, reference = heart_test_set$target)

model_results <- bind_rows(model_results, 
                           tibble(Method="Random Forest",
                                  Accuracy = cm_rf$overall[["Accuracy"]],
                                  Sensitivity = cm_rf$byClass[["Sensitivity"]],
                                  Specificity = cm_rf$byClass[["Specificity"]]))              


```


The results produced by each model are presented in the *Results* section below.
\newline

# Results

The results for each model were as follows. Note that the "overall accuracy" of each model was used to assess its accuracy; but sensitivity and specificity were also reported to better understand the performance of each model.
\newline

```{r display-results}

# Display the results from all of the models.
knitr::kable(model_results)

```

In descending order of accuracy, the results were as follows. 
\newline


```{r reorder-results}

# Display the models sorted in descending order of accuracy.
knitr::kable(model_results %>% arrange(desc(Accuracy)))


```

As shown above, the Linear Discriminant Analysis model produced the most accurate predictions, with an overall accuracy of approximately 81.9%. It also exhibited a reasonable level of sensitivity of 88.75%.
\newline

# Conclusion

This project explored the use of various models to predict the presence of heart disease, and identified the model that produced the most accurate predictions, using the Cleveland heart disease dataset. 

The most accurate predictions were generated using Linear Discriminant Analysis, which had an overall accuracy of approximately 81.9% when applied to the test set. The Random Forest model had a slightly lower overall accuracy of 81.2%. 

There were some limitations on the analysis that could be performed, including the following:

* The *cleveland_heart_disease* dataset used in the modelling was relatively small (297 observations), and partitioned into training and test sets of only 148 and 149 observations respectively. Similar datasets were available from other locations (Long Beach, Hungary, and Switzerland) but they contained a large number of missing values. This made them much less suitable for modelling purposes compared to the Cleveland dataset, which was relatively clean and complete.

* It is likely that most of the patients lived in the same, relatively small (in global terms) geographic region. The modelling might not accurately predict heart disease in patients from other regions or countries, where various environmental, economic and lifestyle factors could impact people's cardiovascular health very differently.

While the Linear Discriminant Analysis and Random Forest models produced moderately accurate predictions, it is questionable that they would be sufficient on their own to be used for clinical purposes. At best, they might be able to be used in combination with other tools or techniques to assist in predicting or diagnosing the presence of heart disease.
